# Default values for spark chart.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# meta:
#   owner:
#   gitrepo:

replicaCount: 1

project:
  # default service/component name, free to change
  component: gdt
  namespace: gdt

appLabels:
  # custom:
  #   key: value
  custom: {}

image:
  repository: rehanann/spark-py
  tag: 3.4.0-extended-1
  pullPolicy: Always
  command: ["/bin/bash"]
  # args: []
  # args:
  #   ["-c", "/opt/spark/bin/spark-submit /opt/spark/work-dir/shared/test2.py"]
#  command: ["/opt/spark/bin/spark-submit"]
# environment variables
envVars:
  driver:
    SPARK_LOG_DIR: /opt/spark/work-dir
  executor:
    SPARK_LOG_DIR: /opt/spark/work-dir

sidecars:
  gitInitContainer:
    enabled: false
    image: rehanann/git-pull:v1.0
    env:
      - name: GIT_PULL_USERNAME
        secret: git-pull-secret
        key: git-username
      - name: GIT_PULL_PASSWORD
        secret: git-pull-secret
        key: git-password
      - name: GIT_REPO_URL
        secret: git-pull-secret
        key: git-repo-url
  s3InitContainer:
    enabled: false
    image: rehanann/pull-data-s3:v1.0
    command: ["/bin/bash", "-c"]
    args:
      - |
        echo "Pulling data from S3..."
        echo "Data pull from S3 completed."
    env:
      - name: MINIO_USERNAME
        secret: minio-secret
        key: username
      - name: MINIO_PASSWORD
        secret: minio-secret
        key: password

# This allow to add any required key values to spark configuration, unless it should not duplicated.
# e.g.
# sparkconf:
#  spark.sql.maxPlanStringLength: "2147483632"
sparkConf:
  # spark.history.fs.logDirectory: s3a://historyserver/logs
  # spark.hadoop.fs.s3a.endpoint: http://minio.default.svc.cluster.local:9000
  # spark.hadoop.fs.s3a.access.key: bU0c4naTz98KynxEsHf1
  # spark.hadoop.fs.s3a.secret.key: dNOkRi7cbUsw0ZHnN9coosKO0iyu21XJpieAayZd
  # spark.hadoop.fs.s3a.path.style.access: true
  # spark.hadoop.fs.s3a.connection.ssl.enabled: false
  # spark.hadoop.fs.s3a.connection.establish.timeout: 60000
  # spark.hadoop.fs.s3a.connection.request.timeout: 60000
  # spark.history.fs.s3a.cleaner.enabled: true
  # spark.history.fs.cleaner.maxAge: 7d
  # spark.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
pyspark:
  python: /usr/bin/python3
  requirements:
    #Fixed configmap file path location to /tmp/requirements.txt, this removes this PVC mandatory requirements.
    filePath: /tmp/pip3_requirements.txt

sparkClientPod:
  required: true

services:
  ui:
    enabled: true
    type: ClusterIP
    port: 4040
  driver:
    enabled: true
    type: ClusterIP
    port: 3000

driver:
  cores: 1
  memory: 1g
  limit:
    cores: 1
  request:
    cores: 1
executor:
  cores: 1
  memory: 1g
  memoryOverhead: 1g
  request:
    cores: 1
  limit:
    cores: 1

resources:
  limits:
    cpu: 1
    memory: 1Gi
  requests:
    cpu: 1
    memory: 1Gi

dynamicAllocation:
  enabled: false
  executorIdleTimeout: 30s
  # Values are chosen based on current YARN setting and existing quotas
  executors:
    minExecutors: 1
    initialExecutors: 1
    maxExecutors: 2
  shuffle:
    # disable external shuffle service, in k8s it is not used
    service:
      enabled: false
    # instead of external shuffle service, tracking of pods which have shuffle blocks is used
    tracking:
      enabled: false
    # timeout for the the pod to keep shuffle blocks
    timeout: 30s

# dependencies: {}

sparkLogs: ERROR

# Below settings control spark 3.5 (log4j2) log level values can be: error, warn, info, debug.
spark35LogLevel: error

sharedVolume:
  enabled: true
  useExisting: true
  mountPath: /opt/spark/work-dir/shared
  existingPvcName: gdt-shared

eventLogs:
  # spark.eventLog.enabled
  enabled: true
  # spark.eventLog.dir
  #  Example for shared PVC
  #  directory: /opt/spark/work-dir/shared/history
  # directory: /tmp/spark-events
  directory: s3a://spark-history-global1/logs

runAsJob: false
